# GermanCodeZero-Agent Windows Native Configuration
# Kopiere diese Datei nach .env für Windows-native Betrieb

# === WINDOWS NATIVE MODE ===
WINDOWS_NATIVE=true
USE_DOCKER=false

# === PATHS (Windows) ===
GCZ_BASE_PATH=%USERPROFILE%\GermanCodeZero
GCZ_DATA_PATH=%USERPROFILE%\GermanCodeZero\data
GCZ_MODELS_PATH=%USERPROFILE%\GermanCodeZero\models
GCZ_WORKSPACE_PATH=%USERPROFILE%\GermanCodeZero\workspace

# === SERVICE URLS (Alle Windows-nativ) ===
# Ollama (nativ installiert)
OLLAMA_HOST=http://localhost:11434

# PostgreSQL (Windows-Installation)
DATABASE_URL=postgresql://gcz_agent:gcz_secure_2024@localhost:5432/germancodezero
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=germancodezero
POSTGRES_USER=gcz_agent
POSTGRES_PASSWORD=gcz_secure_2024

# Redis (Windows-Port)
REDIS_URL=redis://localhost:6379

# Qdrant (Windows-Binary)
QDRANT_URL=http://localhost:6333
QDRANT_GRPC_PORT=6334

# n8n (via npm global)
N8N_URL=http://localhost:5678
N8N_BASIC_AUTH_USER=admin
N8N_BASIC_AUTH_PASSWORD=gcz2024

# === GPU SETTINGS (DirectML/Vulkan) ===
USE_DIRECTML=true
USE_VULKAN=false
OLLAMA_NUM_GPU=999
OLLAMA_GPU_DRIVER=directml
GPU_LAYERS=-1

# === MODEL SETTINGS ===
# Schwere Modelle (DirectML auf GPU)
HEAVY_MODEL_LOCATION=native
DEFAULT_REASONING_MODEL=llama3:70b-instruct-q4_K_M
DEFAULT_CODE_MODEL=deepseek-coder:33b-instruct-q4_K_M

# Leichte Modelle (CPU oder GPU)
LIGHT_MODEL_LOCATION=native
DEFAULT_LIGHT_MODEL=mistral:7b-instruct-q4_K_M
DEFAULT_EMBEDDING_MODEL=nomic-embed-text:latest

# === AGENT SETTINGS ===
AGENT_REGISTRY_PATH=%USERPROFILE%\GermanCodeZero\data\registry.db
AGENT_LOG_LEVEL=INFO
AGENT_MAX_RETRIES=3

# === MONITORING ===
ENABLE_MONITORING=true
METRICS_PORT=9090

# === API SETTINGS ===
API_HOST=0.0.0.0
API_PORT=8000

# === WINDOWS SPECIFIC ===
# Python executable (wenn spezifischer Pfad nötig)
# PYTHON_EXECUTABLE=C:\Python311\python.exe

# Node.js für n8n (wenn nicht in PATH)
# NODE_EXECUTABLE=C:\Program Files\nodejs\node.exe

# Service-Management
SERVICE_START_DELAY=5
SERVICE_HEALTH_CHECK_INTERVAL=60